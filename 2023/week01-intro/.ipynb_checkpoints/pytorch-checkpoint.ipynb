{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J53LFU9oQVlK"
   },
   "source": [
    "# Вспоминаем DL и PyTorch\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/puhsu/dl-hse/blob/master/week01-intro/pytorch.ipynb)\n",
    "\n",
    "\n",
    "Над дз работали:\n",
    "- Алексей Озерин\n",
    "- Никита Корягин\n",
    "- Ваня Рубачёв\n",
    "\n",
    "В этом задании мы вспомним как пользоваться торчем на простых примерах. Если вы всё знаете, можете сдать в anytask любой пример подтверждение вашего profficiency с торчем (курсовая, личный проект).\n",
    "\n",
    "Если есть сомнения, лучше порешать ноутбук, будет полезно в следующих ДЗ.\n",
    "\n",
    "План задания (в скобках баллы):\n",
    "- Базовые операции и autograd в pytorch (0.25)\n",
    "  - обучаем регрессию на low-level торче\n",
    "  - **бонус (0.5)**: https://github.com/srush/Tensor-Puzzles\n",
    "- High level API\n",
    "  - Реализуем простой ResNet (0.5)\n",
    "  - Файнтюним ResNet (0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alvOhaG_Y8w5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PyTorch `(0.2/1)`\n",
    "\n",
    "\n",
    "На оффсайте https://pytorch.org/get-started надо выбрать подходящую конфигурацию и установить пакеты pytorch (версия 2.0.1) и соответствующий torchvision.\n",
    "\n",
    "На своей машине бывает удобно устанавливать нужные версии python, pytorch и torchvision в [виртуальное окружение](https://docs.python.org/3/tutorial/venv.html). Проще всего это делать с помощью конды. Минимальная one binary версия конды с быстрым солвером: [micromamba](https://mamba.readthedocs.io/en/latest/micromamba-installation.html). Создание окружения с последним торчем с поддержкой гпу выглядит как-то так:\n",
    "\n",
    "```shell\n",
    "curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n",
    "mv bin/micromamba /usr/local/bin  # optionall, put micromamba to the PATH\n",
    "eval \"$(./bin/micromamba shell hook -s posix)\"\n",
    "\n",
    "micromamba create -n hse-dl \\\n",
    "-c nvidia \\\n",
    "-c conda-forge \\\n",
    "-c nodefaults \\\n",
    "pytorch::pytorch=2.0.1 \\\n",
    "pytorch::pytorch-cuda=11.8 \\\n",
    "tqdm \\\n",
    "tensorboard \\\n",
    "jupyterlab\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "В Google Colab на осень 2023 уже установлены нужные версии pytorch и torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDDd8zvPY8w_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_ru21cQY8xK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# numpy world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "print(\"X :\\n %s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", np.dot(x, x.T))\n",
    "print(\"mean over cols :\\n%s\" % (x.mean(axis=-1)))\n",
    "print(\"cumsum of cols :\\n%s\" % (np.cumsum(x, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NqOKnrFY8xQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pytorch world\n",
    "\n",
    "x = np.arange(16).reshape(4, 4)\n",
    "\n",
    "x = torch.from_numpy(x).to(dtype=torch.float32) # or torch.arange(0,16).view(4,4)\n",
    "\n",
    "print(\"X :\\n%s\" % x)\n",
    "print(\"add 5 :\\n%s\" % (x + 5))\n",
    "print(\"X*X^T  :\\n\", torch.matmul(x, x.transpose(1, 0)))\n",
    "print(\"mean over cols :\\n\", torch.mean(x, dim=-1))\n",
    "print(\"cumsum of cols :\\n\", torch.cumsum(x, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxJiOWdJY8xW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NumPy vs Pytorch\n",
    "\n",
    "Numpy и Pytorch не требуют описания статического графа вычислений.\n",
    "\n",
    "Можно отлаживаться с помощью pdb или просто print.\n",
    "\n",
    "API несколько различается:\n",
    "\n",
    "```\n",
    "x.reshape([1,2,8]) -> x.view(1,2,8)\n",
    "x.sum(axis=-1) -> x.sum(dim=-1)\n",
    "x.astype('int64') -> x.type(torch.int64)\n",
    "```\n",
    "\n",
    "\n",
    "Легко конвертировать между собой:\n",
    "\n",
    "```\n",
    "torch.from_numpy(npx) -- вернет Tensor\n",
    "tt.numpy() -- вернет Numpy Array\n",
    "```\n",
    "\n",
    "Преобразовать тензор из одного числа в обычное питоновское число:\n",
    "```\n",
    "torch.tensor([1]).item() -> 1\n",
    "```\n",
    "\n",
    "\n",
    "Если что:\n",
    "- смотрите документацию https://pytorch.org/docs/\n",
    "- гуглите (Stackoverflow/tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWKDglA_Y8xX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 2 * np.pi, 16, dtype=torch.float64)\n",
    "\n",
    "# Mini-task: compute a vector of sin^2(x) + cos^2(x)\n",
    "out = NotImplemented\n",
    "\n",
    "print(out.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvBccGm8Y8xh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Automatic gradients\n",
    "\n",
    "У каждого тензора в Pytorch есть флаг `requires_grad`, который отвечает за автоматическое вычисление градиентов:\n",
    "\n",
    "1. Создать переменную: `a = torch.tensor(..., requires_grad=True)`\n",
    "\n",
    "2. Определить какую-нибудь дифференцируемую функцию `loss = whatever(a)`\n",
    "\n",
    "3. Запросить обратный проход `loss.backward()`\n",
    "\n",
    "4. Градиенты будут доступны в `a.grads`\n",
    "\n",
    "\n",
    "Есть два важных отличия Pytorch от Theano/TF:\n",
    "\n",
    "1. Функцию ошибки можно изменять динамически, например на каждом минибатче.\n",
    "\n",
    "2. После вычисления `.backward()` градиенты сохраняются в `.grad` каждой задействованной переменной, при повторных вызовах градиенты суммируются. Это позволяет использовать несколько функций ошибок или виртуально увеличивать batch_size. Поэтому, после каждого шага оптимизатора градиенты стоит обнулять (или [присваивать им None](https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html) для экономии памяти).\n",
    "\n",
    "\n",
    "\n",
    "### Leaf vs Non-leaf Variable:\n",
    "```\n",
    "x = torch.tensor([1., 2., 3., 4.], requires_grad=True))  # leaf tensor\n",
    "y = x + 1  # not a leaf variable\n",
    "```\n",
    "\n",
    "Градиенты будут сохранены и доступны для использования только для `leaf tensor`.\n",
    "Такое поведение по-умолчанию сделано ради экономии памяти. Все тензоры с флагом `requires_grad = False` считаются `leaf tensors` по умолчанию.\n",
    "\n",
    "\n",
    "Обратите внимание, что вычисление градиентов работает только для тензоров с вещественным типом данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCMFdtG1kbKo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# will not work\n",
    "x = torch.tensor([1, 2, 3, 4], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zIjcCUJ1T1V",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Чтобы выставить флаг `requires_grad=False` и выключить автоматическое вычисление градиентов для нескольких тензоров, можно использовать `with torch.no_grad()`, `detach` или `torch.inference_mode` (подробнее о различиях между ними [здесь](https://pytorch.org/docs/stable/notes/autograd.html#locally-disabling-gradient-computation)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JQjCVpb1Uy1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "y = x**2\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.exp(x)\n",
    "    print(z.requires_grad)\n",
    "\n",
    "# detach from the graph\n",
    "w = torch.log(x).detach()\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NHwzSqakbUt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Рассмотрим пример линейной регрессии на датасете the California housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sVwJ5DfY8xj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "x, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "# select one column for simplicity.\n",
    "torch.manual_seed(0)\n",
    "idx = torch.randperm(x.shape[0])[:1000]\n",
    "\n",
    "x = x[idx, 0] / x[idx, 0].std()\n",
    "y = y[idx] / y[idx].std()\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqXtxfdjY8xr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# data tensors\n",
    "x = torch.from_numpy(x).to(dtype=torch.float32)\n",
    "y = torch.from_numpy(y).to(dtype=torch.float32)\n",
    "\n",
    "# все тензоры являются leaf-tensors\n",
    "# x и y не требуют вычисления градиентов\n",
    "for vv in [w, b, x, y]:\n",
    "    print(vv.is_leaf, vv.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxTI1pQhY8x2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# compute the loss\n",
    "y_pred = w * x + b\n",
    "loss = torch.mean((y_pred - y)**2)\n",
    "\n",
    "# automatically compute the gradients for leaf nodes\n",
    "loss.backward()\n",
    "\n",
    "# now w.grad is a tensor containing gradient of L w.r.t. w\n",
    "print(\"dL/dw = \\n\", w.grad)\n",
    "print(\"dL/db = \\n\", b.grad)\n",
    "\n",
    "# no gradients for tensors with requires_grad=False\n",
    "# and non-leaf tensors\n",
    "print(\"Non-Leaf x dL/dx = \\n\", x.grad)\n",
    "print(\"Non-Leaf loss dL/dpred = \\n\", y_pred.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWC6fHzWY8x6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Градиенты промежуточных вершин**\n",
    "\n",
    "В графе, который мы описали `x` и `y_pread` не являются листовыми вершинами. По умолчанию для них не сохраняются градиенты.\n",
    "\n",
    "Для промежуточных вершин мы можем запросить сохранение градиентов с помощью функции `.retain_grad()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsPhBEdlY8x7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = w * x + b\n",
    "\n",
    "# check this:\n",
    "y_pred.retain_grad()\n",
    "\n",
    "loss = torch.mean((y_pred - y)**2)\n",
    "loss.backward()\n",
    "\n",
    "print(\"Non-Leaf loss dL/dpred = \\n\", y_pred.grad[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUE_HlYmus5o"
   },
   "source": [
    "Теперь давайте **обучим параметр**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8om5HRwusKx"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# model tensors\n",
    "w = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "for i in range(100):\n",
    "    # TODO compute loss\n",
    "    y_pred = NotImplemented\n",
    "    loss = NotImplemented\n",
    "\n",
    "    # backprop and gradient descent\n",
    "    loss.backward()\n",
    "\n",
    "    # Update w, b and set grads to zero afterwards TODO\n",
    "    w.data -= learning_rate * w.grad\n",
    "    b.data -= learning_rate * b.grad\n",
    "\n",
    "    w.grad = None\n",
    "    b.grad = None\n",
    "\n",
    "    # The rest of code is just bells and whistles\n",
    "    if (i + 1) % 5 == 0:\n",
    "        # draw linear regression prediction vs data\n",
    "        clear_output(True)\n",
    "        plt.axhline(0, color='gray')\n",
    "        plt.axvline(0, color='gray')\n",
    "        plt.scatter(x.numpy(), y.numpy())\n",
    "        plt.plot(x.numpy(), y_pred.data.numpy(), color='orange')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"loss = \", loss.item())\n",
    "        if loss.item() < 0.5:\n",
    "            print(\"Done!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffrl8GpUo4Gp"
   },
   "source": [
    "### Ресурсы\n",
    "\n",
    "Если хотите вспомнить как работает backpropagation и autograd и как устроен PyTorch-like API изнутри, рекомендуем\n",
    "- видео [The spelled-out intro to neural networks and backpropagation: building micrograd ](https://www.youtube.com/watch?v=VMj-3S1tku0)\n",
    "- блогпост https://colah.github.io/posts/2015-08-Backprop про backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9og-cfPqpk2V"
   },
   "source": [
    "## **Bonus** Tensor Puzzles `(0.5/1)`\n",
    "\n",
    "Если не очень комфортно чувствуете себя с операциями в тензорных либах (например, не помните что такое broadcasting) можете порешать задачки из https://github.com/srush/Tensor-Puzzles. Это бонусное задание, ниже просто копипаста колаба Tensor-Puzzles для удобства. Делайте и сдавайте всё в этом ноутбуке.\n",
    "\n",
    "---\n",
    "\n",
    "### Tensor Puzzles\n",
    "- by [Sasha Rush](http://rush-nlp.com) - [srush_nlp](https://twitter.com/srush_nlp) (with Marcos Treviso)\n",
    "\n",
    "When learning a tensor programming language like PyTorch or Numpy it\n",
    "is tempting to rely on the standard library (or more honestly\n",
    "StackOverflow) to find a magic function for everything.  But in\n",
    "practice, the tensor language is extremely expressive, and you can\n",
    "do most things from first principles and clever use of broadcasting.\n",
    "\n",
    "This is a collection of 21 tensor puzzles. Like chess puzzles these are\n",
    "not meant to simulate the complexity of a real program, but to practice\n",
    "in a simplified environment. Each puzzle asks you to reimplement one\n",
    "function in the NumPy standard library without magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:04.415840Z",
     "iopub.status.busy": "2022-07-13T00:15:04.415474Z",
     "iopub.status.idle": "2022-07-13T00:15:15.033050Z",
     "shell.execute_reply": "2022-07-13T00:15:15.032260Z"
    },
    "id": "a80d8a77"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq torchtyping hypothesis pytest git+https://github.com/chalk-diagrams/chalk\n",
    "!wget -q https://github.com/srush/Tensor-Puzzles/raw/main/lib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:15.036937Z",
     "iopub.status.busy": "2022-07-13T00:15:15.036583Z",
     "iopub.status.idle": "2022-07-13T00:15:16.650907Z",
     "shell.execute_reply": "2022-07-13T00:15:16.650254Z"
    },
    "id": "bf221907"
   },
   "outputs": [],
   "source": [
    "from lib import draw_examples, make_test, run_test\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchtyping import TensorType as TT\n",
    "tensor = torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b4f584e"
   },
   "source": [
    "#### Rules\n",
    "\n",
    "1. These puzzles are about *broadcasting*. Know this rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e2fdc64",
    "lines_to_next_cell": 2
   },
   "source": [
    "![](https://pbs.twimg.com/media/FQywor0WYAssn7Y?format=png&name=large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7015885"
   },
   "source": [
    "2. Each puzzle needs to be solved in 1 line (<80 columns) of code.\n",
    "3. You are allowed @, arithmetic, comparison, `shape`, any indexing (e.g. `a[:j], a[:, None], a[arange(10)]`), and previous puzzle functions.\n",
    "4. You are *not allowed* anything else. No `view`, `sum`, `take`, `squeeze`, `tensor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc2cbfb3"
   },
   "source": [
    "5. You can start with these two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:16.654641Z",
     "iopub.status.busy": "2022-07-13T00:15:16.654307Z",
     "iopub.status.idle": "2022-07-13T00:15:16.697912Z",
     "shell.execute_reply": "2022-07-13T00:15:16.697280Z"
    },
    "id": "1e917499",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def arange(i: int):\n",
    "    \"Use this function to replace a for-loop.\"\n",
    "    return torch.tensor(range(i))\n",
    "\n",
    "draw_examples(\"arange\", [{\"\" : arange(i)} for i in [5, 3, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:16.701951Z",
     "iopub.status.busy": "2022-07-13T00:15:16.701616Z",
     "iopub.status.idle": "2022-07-13T00:15:16.795294Z",
     "shell.execute_reply": "2022-07-13T00:15:16.794635Z"
    },
    "id": "aa922d9d"
   },
   "outputs": [],
   "source": [
    "# Example of broadcasting.\n",
    "examples = [(arange(4), arange(5)[:, None]) ,\n",
    "            (arange(3)[:, None], arange(2))]\n",
    "draw_examples(\"broadcast\", [{\"a\": a, \"b\":b, \"ret\": a + b} for a, b in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:16.799098Z",
     "iopub.status.busy": "2022-07-13T00:15:16.798780Z",
     "iopub.status.idle": "2022-07-13T00:15:16.910897Z",
     "shell.execute_reply": "2022-07-13T00:15:16.910310Z"
    },
    "id": "0554b7e3",
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def where(q, a, b):\n",
    "    \"Use this function to replace an if-statement.\"\n",
    "    return (q * a) + (~q) * b\n",
    "\n",
    "# In diagrams, orange is positive/True, where is zero/False, and blue is negative.\n",
    "\n",
    "examples = [(tensor([False]), tensor([10]), tensor([0])),\n",
    "            (tensor([False, True]), tensor([1, 1]), tensor([-10, 0])),\n",
    "            (tensor([False, True]), tensor([1]), tensor([-10, 0])),\n",
    "            (tensor([[False, True], [True, False]]), tensor([1]), tensor([-10, 0])),\n",
    "            (tensor([[False, True], [True, False]]), tensor([[0], [10]]), tensor([-10, 0])),\n",
    "           ]\n",
    "draw_examples(\"where\", [{\"q\": q, \"a\":a, \"b\":b, \"ret\": where(q, a, b)} for q, a, b in examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06ef7f29"
   },
   "source": [
    "#### Puzzle 1 - ones\n",
    "\n",
    "Compute [ones](https://numpy.org/doc/stable/reference/generated/numpy.ones.html) - the vector of all ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:16.915061Z",
     "iopub.status.busy": "2022-07-13T00:15:16.914716Z",
     "iopub.status.idle": "2022-07-13T00:15:17.727959Z",
     "shell.execute_reply": "2022-07-13T00:15:17.727364Z"
    },
    "id": "e46e4ada"
   },
   "outputs": [],
   "source": [
    "def ones_spec(out):\n",
    "    for i in range(len(out)):\n",
    "        out[i] = 1\n",
    "\n",
    "def ones(i: int) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_ones = make_test(\"one\", ones, ones_spec, add_sizes=[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:17.731092Z",
     "iopub.status.busy": "2022-07-13T00:15:17.730771Z",
     "iopub.status.idle": "2022-07-13T00:15:17.734462Z",
     "shell.execute_reply": "2022-07-13T00:15:17.733881Z"
    },
    "id": "65dadb3d",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d281e56c"
   },
   "source": [
    "#### Puzzle 2 - sum\n",
    "\n",
    "Compute [sum](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) - the sum of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:17.737503Z",
     "iopub.status.busy": "2022-07-13T00:15:17.737190Z",
     "iopub.status.idle": "2022-07-13T00:15:18.496977Z",
     "shell.execute_reply": "2022-07-13T00:15:18.496351Z"
    },
    "id": "eb9f236f"
   },
   "outputs": [],
   "source": [
    "def sum_spec(a, out):\n",
    "    out[0] = 0\n",
    "    for i in range(len(a)):\n",
    "        out[0] += a[i]\n",
    "\n",
    "def sum(a: TT[\"i\"]) -> TT[1]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_sum = make_test(\"sum\", sum, sum_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:18.500120Z",
     "iopub.status.busy": "2022-07-13T00:15:18.499809Z",
     "iopub.status.idle": "2022-07-13T00:15:18.503156Z",
     "shell.execute_reply": "2022-07-13T00:15:18.502577Z"
    },
    "id": "3f7e2b46",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b2d68c4"
   },
   "source": [
    "#### Puzzle 3 - outer\n",
    "\n",
    "Compute [outer](https://numpy.org/doc/stable/reference/generated/numpy.outer.html) - the outer product of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:18.506196Z",
     "iopub.status.busy": "2022-07-13T00:15:18.505868Z",
     "iopub.status.idle": "2022-07-13T00:15:20.019439Z",
     "shell.execute_reply": "2022-07-13T00:15:20.018755Z"
    },
    "id": "33e8b424"
   },
   "outputs": [],
   "source": [
    "def outer_spec(a, b, out):\n",
    "    for i in range(len(out)):\n",
    "        for j in range(len(out[0])):\n",
    "            out[i][j] = a[i] * b[j]\n",
    "\n",
    "def outer(a: TT[\"i\"], b: TT[\"j\"]) -> TT[\"i\", \"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_outer = make_test(\"outer\", outer, outer_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:20.022830Z",
     "iopub.status.busy": "2022-07-13T00:15:20.022513Z",
     "iopub.status.idle": "2022-07-13T00:15:20.026801Z",
     "shell.execute_reply": "2022-07-13T00:15:20.026186Z"
    },
    "id": "15c04a58"
   },
   "outputs": [],
   "source": [
    "# run_test(test_outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebb1a810"
   },
   "source": [
    "#### Puzzle 4 - diag\n",
    "\n",
    "Compute [diag](https://numpy.org/doc/stable/reference/generated/numpy.diag.html) - the diagonal vector of a square matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:20.030049Z",
     "iopub.status.busy": "2022-07-13T00:15:20.029731Z",
     "iopub.status.idle": "2022-07-13T00:15:21.274448Z",
     "shell.execute_reply": "2022-07-13T00:15:21.273836Z"
    },
    "id": "09ea72c6"
   },
   "outputs": [],
   "source": [
    "def diag_spec(a, out):\n",
    "    for i in range(len(a)):\n",
    "        out[i] = a[i][i]\n",
    "\n",
    "def diag(a: TT[\"i\", \"i\"]) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_diag = make_test(\"diag\", diag, diag_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:21.277837Z",
     "iopub.status.busy": "2022-07-13T00:15:21.277486Z",
     "iopub.status.idle": "2022-07-13T00:15:21.281005Z",
     "shell.execute_reply": "2022-07-13T00:15:21.280409Z"
    },
    "id": "5d4c3641"
   },
   "outputs": [],
   "source": [
    "# run_test(test_diag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ffdce80"
   },
   "source": [
    "#### Puzzle 5 - eye\n",
    "\n",
    "Compute [eye](https://numpy.org/doc/stable/reference/generated/numpy.eye.html) - the identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:21.283997Z",
     "iopub.status.busy": "2022-07-13T00:15:21.283689Z",
     "iopub.status.idle": "2022-07-13T00:15:22.155854Z",
     "shell.execute_reply": "2022-07-13T00:15:22.155222Z"
    },
    "id": "4fda43df"
   },
   "outputs": [],
   "source": [
    "def eye_spec(out):\n",
    "    for i in range(len(out)):\n",
    "        out[i][i] = 1\n",
    "\n",
    "def eye(j: int) -> TT[\"j\", \"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_eye = make_test(\"eye\", eye, eye_spec, add_sizes=[\"j\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:22.159088Z",
     "iopub.status.busy": "2022-07-13T00:15:22.158772Z",
     "iopub.status.idle": "2022-07-13T00:15:22.162208Z",
     "shell.execute_reply": "2022-07-13T00:15:22.161597Z"
    },
    "id": "1c2ec691"
   },
   "outputs": [],
   "source": [
    "# run_test(test_eye)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ceb0fdd"
   },
   "source": [
    "#### Puzzle 6 - triu\n",
    "\n",
    "Compute [triu](https://numpy.org/doc/stable/reference/generated/numpy.triu.html) - the upper triangular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:22.165226Z",
     "iopub.status.busy": "2022-07-13T00:15:22.164922Z",
     "iopub.status.idle": "2022-07-13T00:15:23.160949Z",
     "shell.execute_reply": "2022-07-13T00:15:23.160294Z"
    },
    "id": "4658f7e5"
   },
   "outputs": [],
   "source": [
    "def triu_spec(out):\n",
    "    for i in range(len(out)):\n",
    "        for j in range(len(out)):\n",
    "            if i <= j:\n",
    "                out[i][j] = 1\n",
    "            else:\n",
    "                out[i][j] = 0\n",
    "\n",
    "def triu(j: int) -> TT[\"j\", \"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_triu = make_test(\"triu\", triu, triu_spec, add_sizes=[\"j\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:23.164309Z",
     "iopub.status.busy": "2022-07-13T00:15:23.163987Z",
     "iopub.status.idle": "2022-07-13T00:15:23.167373Z",
     "shell.execute_reply": "2022-07-13T00:15:23.166786Z"
    },
    "id": "b00e3f88"
   },
   "outputs": [],
   "source": [
    "# run_test(test_triu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3209ef8"
   },
   "source": [
    "#### Puzzle 7 - cumsum\n",
    "\n",
    "Compute [cumsum](https://numpy.org/doc/stable/reference/generated/numpy.cumsum.html) - the cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:23.170337Z",
     "iopub.status.busy": "2022-07-13T00:15:23.170024Z",
     "iopub.status.idle": "2022-07-13T00:15:24.239732Z",
     "shell.execute_reply": "2022-07-13T00:15:24.239081Z"
    },
    "id": "997ee763"
   },
   "outputs": [],
   "source": [
    "def cumsum_spec(a, out):\n",
    "    total = 0\n",
    "    for i in range(len(out)):\n",
    "        out[i] = total + a[i]\n",
    "        total += a[i]\n",
    "\n",
    "def cumsum(a: TT[\"i\"]) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_cumsum = make_test(\"cumsum\", cumsum, cumsum_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:24.243017Z",
     "iopub.status.busy": "2022-07-13T00:15:24.242709Z",
     "iopub.status.idle": "2022-07-13T00:15:24.246110Z",
     "shell.execute_reply": "2022-07-13T00:15:24.245551Z"
    },
    "id": "9145d1cc",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15c09fb6"
   },
   "source": [
    "#### Puzzle 8 - diff\n",
    "\n",
    "Compute [diff](https://numpy.org/doc/stable/reference/generated/numpy.diff.html) - the running difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:24.249200Z",
     "iopub.status.busy": "2022-07-13T00:15:24.248891Z",
     "iopub.status.idle": "2022-07-13T00:15:25.183613Z",
     "shell.execute_reply": "2022-07-13T00:15:25.182987Z"
    },
    "id": "47d86d1f"
   },
   "outputs": [],
   "source": [
    "def diff_spec(a, out):\n",
    "    out[0] = a[0]\n",
    "    for i in range(1, len(out)):\n",
    "        out[i] = a[i] - a[i - 1]\n",
    "\n",
    "def diff(a: TT[\"i\"], i: int) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_diff = make_test(\"diff\", diff, diff_spec, add_sizes=[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:25.186875Z",
     "iopub.status.busy": "2022-07-13T00:15:25.186557Z",
     "iopub.status.idle": "2022-07-13T00:15:25.190034Z",
     "shell.execute_reply": "2022-07-13T00:15:25.189482Z"
    },
    "id": "bb4eeff6"
   },
   "outputs": [],
   "source": [
    "# run_test(test_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74c616c6"
   },
   "source": [
    "#### Puzzle 9 - vstack\n",
    "\n",
    "Compute [vstack](https://numpy.org/doc/stable/reference/generated/numpy.vstack.html) - the matrix of two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:25.193149Z",
     "iopub.status.busy": "2022-07-13T00:15:25.192804Z",
     "iopub.status.idle": "2022-07-13T00:15:26.641528Z",
     "shell.execute_reply": "2022-07-13T00:15:26.640905Z"
    },
    "id": "20a69840"
   },
   "outputs": [],
   "source": [
    "def vstack_spec(a, b, out):\n",
    "    for i in range(len(out[0])):\n",
    "        out[0][i] = a[i]\n",
    "        out[1][i] = b[i]\n",
    "\n",
    "def vstack(a: TT[\"i\"], b: TT[\"i\"]) -> TT[2, \"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_vstack = make_test(\"vstack\", vstack, vstack_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:26.644713Z",
     "iopub.status.busy": "2022-07-13T00:15:26.644397Z",
     "iopub.status.idle": "2022-07-13T00:15:26.647729Z",
     "shell.execute_reply": "2022-07-13T00:15:26.647154Z"
    },
    "id": "e6cb449b"
   },
   "outputs": [],
   "source": [
    "# run_test(test_vstack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3f8a5ae"
   },
   "source": [
    "#### Puzzle 10 - roll\n",
    "\n",
    "Compute [roll](https://numpy.org/doc/stable/reference/generated/numpy.roll.html) - the vector shifted 1 circular position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:26.650696Z",
     "iopub.status.busy": "2022-07-13T00:15:26.650381Z",
     "iopub.status.idle": "2022-07-13T00:15:27.752738Z",
     "shell.execute_reply": "2022-07-13T00:15:27.752117Z"
    },
    "id": "7962491f"
   },
   "outputs": [],
   "source": [
    "def roll_spec(a, out):\n",
    "    for i in range(len(out)):\n",
    "        if i + 1 < len(out):\n",
    "            out[i] = a[i + 1]\n",
    "        else:\n",
    "            out[i] = a[i + 1 - len(out)]\n",
    "\n",
    "def roll(a: TT[\"i\"], i: int) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_roll = make_test(\"roll\", roll, roll_spec, add_sizes=[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:27.755891Z",
     "iopub.status.busy": "2022-07-13T00:15:27.755582Z",
     "iopub.status.idle": "2022-07-13T00:15:27.758982Z",
     "shell.execute_reply": "2022-07-13T00:15:27.758408Z"
    },
    "id": "09103327"
   },
   "outputs": [],
   "source": [
    "# run_test(test_roll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adc7dcdd"
   },
   "source": [
    "#### Puzzle 11 - flip\n",
    "\n",
    "Compute [flip](https://numpy.org/doc/stable/reference/generated/numpy.flip.html) - the reversed vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:27.762023Z",
     "iopub.status.busy": "2022-07-13T00:15:27.761718Z",
     "iopub.status.idle": "2022-07-13T00:15:28.745412Z",
     "shell.execute_reply": "2022-07-13T00:15:28.744797Z"
    },
    "id": "1f2d83bb"
   },
   "outputs": [],
   "source": [
    "def flip_spec(a, out):\n",
    "    for i in range(len(out)):\n",
    "        out[i] = a[len(out) - i - 1]\n",
    "\n",
    "def flip(a: TT[\"i\"], i: int) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_flip = make_test(\"flip\", flip, flip_spec, add_sizes=[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:28.748580Z",
     "iopub.status.busy": "2022-07-13T00:15:28.748257Z",
     "iopub.status.idle": "2022-07-13T00:15:28.751662Z",
     "shell.execute_reply": "2022-07-13T00:15:28.751071Z"
    },
    "id": "e5168678"
   },
   "outputs": [],
   "source": [
    "# run_test(test_flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa4469eb"
   },
   "source": [
    "#### Puzzle 12 - compress\n",
    "\n",
    "\n",
    "Compute [compress](https://numpy.org/doc/stable/reference/generated/numpy.compress.html) - keep only masked entries (left-aligned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:28.754592Z",
     "iopub.status.busy": "2022-07-13T00:15:28.754290Z",
     "iopub.status.idle": "2022-07-13T00:15:30.055478Z",
     "shell.execute_reply": "2022-07-13T00:15:30.054841Z"
    },
    "id": "f49b8303"
   },
   "outputs": [],
   "source": [
    "def compress_spec(g, v, out):\n",
    "    j = 0\n",
    "    for i in range(len(g)):\n",
    "        if g[i]:\n",
    "            out[j] = v[i]\n",
    "            j += 1\n",
    "\n",
    "def compress(g: TT[\"i\", bool], v: TT[\"i\"], i:int) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_compress = make_test(\"compress\", compress, compress_spec, add_sizes=[\"i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:30.058645Z",
     "iopub.status.busy": "2022-07-13T00:15:30.058336Z",
     "iopub.status.idle": "2022-07-13T00:15:30.061763Z",
     "shell.execute_reply": "2022-07-13T00:15:30.061166Z"
    },
    "id": "9e98d290",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_compress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e944d79",
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Puzzle 13 - pad_to\n",
    "\n",
    "\n",
    "Compute pad_to - eliminate or add 0s to change size of vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:30.064726Z",
     "iopub.status.busy": "2022-07-13T00:15:30.064418Z",
     "iopub.status.idle": "2022-07-13T00:15:31.162878Z",
     "shell.execute_reply": "2022-07-13T00:15:31.162268Z"
    },
    "id": "52988720"
   },
   "outputs": [],
   "source": [
    "def pad_to_spec(a, out):\n",
    "    for i in range(min(len(out), len(a))):\n",
    "        out[i] = a[i]\n",
    "\n",
    "\n",
    "def pad_to(a: TT[\"i\"], i: int, j: int) -> TT[\"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "test_pad_to = make_test(\"pad_to\", pad_to, pad_to_spec, add_sizes=[\"i\", \"j\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:31.166060Z",
     "iopub.status.busy": "2022-07-13T00:15:31.165749Z",
     "iopub.status.idle": "2022-07-13T00:15:31.169131Z",
     "shell.execute_reply": "2022-07-13T00:15:31.168580Z"
    },
    "id": "f8e5aee3"
   },
   "outputs": [],
   "source": [
    "# run_test(test_pad_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aee589be"
   },
   "source": [
    "#### Puzzle 14 - sequence_mask\n",
    "\n",
    "\n",
    "Compute [sequence_mask](https://www.tensorflow.org/api_docs/python/tf/sequence_mask) - pad out to length per batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:31.172146Z",
     "iopub.status.busy": "2022-07-13T00:15:31.171799Z",
     "iopub.status.idle": "2022-07-13T00:15:33.292198Z",
     "shell.execute_reply": "2022-07-13T00:15:33.291558Z"
    },
    "id": "6aca6d50"
   },
   "outputs": [],
   "source": [
    "def sequence_mask_spec(values, length, out):\n",
    "    for i in range(len(out)):\n",
    "        for j in range(len(out[0])):\n",
    "            if j < length[i]:\n",
    "                out[i][j] = values[i][j]\n",
    "            else:\n",
    "                out[i][j] = 0\n",
    "\n",
    "def sequence_mask(values: TT[\"i\", \"j\"], length: TT[\"i\", int]) -> TT[\"i\", \"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def constraint_set_length(d):\n",
    "    d[\"length\"] = d[\"length\"] % d[\"values\"].shape[1]\n",
    "    return d\n",
    "\n",
    "\n",
    "test_sequence = make_test(\"sequence_mask\",\n",
    "    sequence_mask, sequence_mask_spec, constraint=constraint_set_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:33.295923Z",
     "iopub.status.busy": "2022-07-13T00:15:33.295590Z",
     "iopub.status.idle": "2022-07-13T00:15:33.299068Z",
     "shell.execute_reply": "2022-07-13T00:15:33.298467Z"
    },
    "id": "f5646e37",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "342fedba",
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Puzzle 15 - bincount\n",
    "\n",
    "Compute [bincount](https://numpy.org/doc/stable/reference/generated/numpy.bincount.html) - count number of times an entry was seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:33.302153Z",
     "iopub.status.busy": "2022-07-13T00:15:33.301837Z",
     "iopub.status.idle": "2022-07-13T00:15:34.370952Z",
     "shell.execute_reply": "2022-07-13T00:15:34.370349Z"
    },
    "id": "b8a0a10c"
   },
   "outputs": [],
   "source": [
    "def bincount_spec(a, out):\n",
    "    for i in range(len(a)):\n",
    "        out[a[i]] += 1\n",
    "\n",
    "def bincount(a: TT[\"i\"], j: int) -> TT[\"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def constraint_set_max(d):\n",
    "    d[\"a\"] = d[\"a\"] % d[\"return\"].shape[0]\n",
    "    return d\n",
    "\n",
    "\n",
    "test_bincount = make_test(\"bincount\",\n",
    "    bincount, bincount_spec, add_sizes=[\"j\"], constraint=constraint_set_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:34.374345Z",
     "iopub.status.busy": "2022-07-13T00:15:34.373778Z",
     "iopub.status.idle": "2022-07-13T00:15:34.377216Z",
     "shell.execute_reply": "2022-07-13T00:15:34.376611Z"
    },
    "id": "0d766aec",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_bincount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ff7e77c",
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Puzzle 16 - scatter_add\n",
    "\n",
    "Compute [scatter_add](https://pytorch-scatter.readthedocs.io/en/1.3.0/functions/add.html) - add together values that link to the same location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:34.380250Z",
     "iopub.status.busy": "2022-07-13T00:15:34.379949Z",
     "iopub.status.idle": "2022-07-13T00:15:35.637090Z",
     "shell.execute_reply": "2022-07-13T00:15:35.636472Z"
    },
    "id": "405a800e"
   },
   "outputs": [],
   "source": [
    "def scatter_add_spec(values, link, out):\n",
    "    for j in range(len(values)):\n",
    "        out[link[j]] += values[j]\n",
    "\n",
    "def scatter_add(values: TT[\"i\"], link: TT[\"i\"], j: int) -> TT[\"j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def constraint_set_max(d):\n",
    "    d[\"link\"] = d[\"link\"] % d[\"return\"].shape[0]\n",
    "    return d\n",
    "\n",
    "\n",
    "test_scatter_add = make_test(\"scatter_add\",\n",
    "    scatter_add, scatter_add_spec, add_sizes=[\"j\"], constraint=constraint_set_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:35.640245Z",
     "iopub.status.busy": "2022-07-13T00:15:35.639897Z",
     "iopub.status.idle": "2022-07-13T00:15:35.643383Z",
     "shell.execute_reply": "2022-07-13T00:15:35.642753Z"
    },
    "id": "a9ea0110",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_scatter_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9020b21b"
   },
   "source": [
    "#### Puzzle 17 - flatten\n",
    "\n",
    "Compute [flatten](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flatten.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:35.646407Z",
     "iopub.status.busy": "2022-07-13T00:15:35.646100Z",
     "iopub.status.idle": "2022-07-13T00:15:37.321766Z",
     "shell.execute_reply": "2022-07-13T00:15:37.321136Z"
    },
    "id": "56c917be",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def flatten_spec(a, out):\n",
    "    k = 0\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a[0])):\n",
    "            out[k] = a[i][j]\n",
    "            k += 1\n",
    "\n",
    "def flatten(a: TT[\"i\", \"j\"], i:int, j:int) -> TT[\"i * j\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_flatten = make_test(\"flatten\", flatten, flatten_spec, add_sizes=[\"i\", \"j\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:37.325238Z",
     "iopub.status.busy": "2022-07-13T00:15:37.324893Z",
     "iopub.status.idle": "2022-07-13T00:15:37.328344Z",
     "shell.execute_reply": "2022-07-13T00:15:37.327760Z"
    },
    "id": "a129e213"
   },
   "outputs": [],
   "source": [
    "# run_test(test_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc61b4eb"
   },
   "source": [
    "#### Puzzle 18 - linspace\n",
    "\n",
    "Compute [linspace](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:37.331326Z",
     "iopub.status.busy": "2022-07-13T00:15:37.330999Z",
     "iopub.status.idle": "2022-07-13T00:15:38.652685Z",
     "shell.execute_reply": "2022-07-13T00:15:38.652037Z"
    },
    "id": "115ef19c"
   },
   "outputs": [],
   "source": [
    "def linspace_spec(i, j, out):\n",
    "    for k in range(len(out)):\n",
    "        out[k] = float(i + (j - i) * k / max(1, len(out) - 1))\n",
    "\n",
    "def linspace(i: TT[1], j: TT[1], n: int) -> TT[\"n\", float]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_linspace = make_test(\"linspace\", linspace, linspace_spec, add_sizes=[\"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:38.655950Z",
     "iopub.status.busy": "2022-07-13T00:15:38.655631Z",
     "iopub.status.idle": "2022-07-13T00:15:38.659029Z",
     "shell.execute_reply": "2022-07-13T00:15:38.658438Z"
    },
    "id": "812a6235",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_linspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d107267"
   },
   "source": [
    "#### Puzzle 19 - heaviside\n",
    "\n",
    "Compute [heaviside](https://numpy.org/doc/stable/reference/generated/numpy.heaviside.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:38.662023Z",
     "iopub.status.busy": "2022-07-13T00:15:38.661722Z",
     "iopub.status.idle": "2022-07-13T00:15:39.902909Z",
     "shell.execute_reply": "2022-07-13T00:15:39.902243Z"
    },
    "id": "3becb5f1"
   },
   "outputs": [],
   "source": [
    "def heaviside_spec(a, b, out):\n",
    "    for k in range(len(out)):\n",
    "        if a[k] == 0:\n",
    "            out[k] = b[k]\n",
    "        else:\n",
    "            out[k] = int(a[k] > 0)\n",
    "\n",
    "def heaviside(a: TT[\"i\"], b: TT[\"i\"]) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_heaviside = make_test(\"heaviside\", heaviside, heaviside_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:39.906141Z",
     "iopub.status.busy": "2022-07-13T00:15:39.905812Z",
     "iopub.status.idle": "2022-07-13T00:15:39.909230Z",
     "shell.execute_reply": "2022-07-13T00:15:39.908641Z"
    },
    "id": "357974e8",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# run_test(test_heaviside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2d00053"
   },
   "source": [
    "#### Puzzle 20 - repeat (1d)\n",
    "\n",
    "Compute [repeat](https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:39.912233Z",
     "iopub.status.busy": "2022-07-13T00:15:39.911925Z",
     "iopub.status.idle": "2022-07-13T00:15:41.190253Z",
     "shell.execute_reply": "2022-07-13T00:15:41.189625Z"
    },
    "id": "f763b7ce"
   },
   "outputs": [],
   "source": [
    "def repeat_spec(a, d, out):\n",
    "    for i in range(d[0]):\n",
    "        for k in range(len(a)):\n",
    "            out[i][k] = a[k]\n",
    "\n",
    "def constraint_set(d):\n",
    "    d[\"d\"][0] = d[\"return\"].shape[0]\n",
    "    return d\n",
    "\n",
    "\n",
    "def repeat(a: TT[\"i\"], d: TT[1]) -> TT[\"d\", \"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_repeat = make_test(\"repeat\", repeat, repeat_spec, constraint=constraint_set)\n",
    "\n",
    "\n",
    "# ## Puzzle 21 - bucketize\n",
    "#\n",
    "# Compute [bucketize](https://pytorch.org/docs/stable/generated/torch.bucketize.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:41.193726Z",
     "iopub.status.busy": "2022-07-13T00:15:41.193384Z",
     "iopub.status.idle": "2022-07-13T00:15:42.586710Z",
     "shell.execute_reply": "2022-07-13T00:15:42.586092Z"
    },
    "id": "7832fda9"
   },
   "outputs": [],
   "source": [
    "def bucketize_spec(v, boundaries, out):\n",
    "    for i, val in enumerate(v):\n",
    "        out[i] = 0\n",
    "        for j in range(len(boundaries)-1):\n",
    "            if val >= boundaries[j]:\n",
    "                out[i] = j + 1\n",
    "        if val >= boundaries[-1]:\n",
    "            out[i] = len(boundaries)\n",
    "\n",
    "\n",
    "def constraint_set(d):\n",
    "    d[\"boundaries\"] = np.abs(d[\"boundaries\"]).cumsum()\n",
    "    return d\n",
    "\n",
    "\n",
    "def bucketize(v: TT[\"i\"], boundaries: TT[\"j\"]) -> TT[\"i\"]:\n",
    "    raise NotImplementedError\n",
    "\n",
    "test_bucketize = make_test(\"bucketize\", bucketize, bucketize_spec,\n",
    "                           constraint=constraint_set)\n",
    "\n",
    "\n",
    "#\n",
    "# # Speed Run Mode!\n",
    "#\n",
    "# What is the smallest you can make each of these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T00:15:42.589966Z",
     "iopub.status.busy": "2022-07-13T00:15:42.589646Z",
     "iopub.status.idle": "2022-07-13T00:15:42.599516Z",
     "shell.execute_reply": "2022-07-13T00:15:42.598869Z"
    },
    "id": "dbf265d8"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "fns = (ones, sum, outer, diag, eye, triu, cumsum, diff, vstack, roll, flip,\n",
    "       compress, pad_to, sequence_mask, bincount, scatter_add)\n",
    "\n",
    "for fn in fns:\n",
    "    lines = [l for l in inspect.getsource(fn).split(\"\\n\") if not l.strip().startswith(\"#\")]\n",
    "\n",
    "    if len(lines) > 3:\n",
    "        print(fn.__name__, len(lines[2]), \"(more than 1 line)\")\n",
    "    else:\n",
    "        print(fn.__name__, len(lines[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEGFT2y5sXkT"
   },
   "source": [
    "## High-Level API\n",
    "\n",
    "В торче также есть более высокоуровневые API для работы с моделями, загрузки данных, оптимизации, распределенного обучения, etc.\n",
    "\n",
    "### Models\n",
    "\n",
    "Чтобы не контролировать переменные с весами по-отдельности. Pytorch предоставляет высокоуровневый API для моделей http://pytorch.org/docs/master/nn.html#torch.nn.Module.\n",
    "\n",
    "Чтобы реализовать свой слой или модель необходимо отнаследоваться от torch.nn.Module, определить параметры/слои в `__init__` (`setattr` либо других `nn.Module`, либо `nn.Parameter`) и описать `forward`. `backward` будет вычислен автоматически (если вы выполняли поддерживаемые autograd операции, иначе надо написать `torch.autograd.Function` руками).\n",
    "\n",
    "\n",
    "### Optimizers\n",
    "\n",
    "Чтобы не итерироваться по всем параметрам модели и не обновлять веса вручную Pytorch предоставляет оптимизаторы с унифицированным интерфейсом:    \n",
    "http://pytorch.org/docs/master/optim.html\n",
    "\n",
    "Напомним, как выглядит градиентный спуск для оптимизации функционала потерь:\n",
    "  \n",
    "$$\\theta^{n+1} = \\theta^{n} - \\alpha \\nabla_{\\theta}L$$\n",
    "\n",
    "Единственным гиперпараметром в нем является $\\alpha$ -- это `learning_rate`.\n",
    "\n",
    "На практике часто используют различные модификации (например _Momentum_):\n",
    "\n",
    "$$\\theta^{n+1} = \\theta^{n} - U^{n}\\\\\n",
    "U^{n} = \\gamma U^{n-1} + \\alpha \\nabla_{\\theta}(L)\n",
    "$$\n",
    "\n",
    "Хороший обзор алгоритмов оптимизации для сетей можно посмотреть [тут](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "- требуется указать список переменных для оптимизации в аргументе `param_groups` (набор `dict`'ов с ключами `params` и гиперпараметрами -- позволяет применять разные гиперпараметры к разным группам весов, например, не применять `weight_decay` к сдвигам)\n",
    "- `opt.step()` применяет `update` ($U^{n}$) к весам\n",
    "- `opt.zero_grad()` сбрасывает градиенты\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "Стандартные операции с данными (загрузить с диска, предобработать, забатчевать, распараллелить считывание)\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3aA8gjI2PPq"
   },
   "source": [
    "### Working with highlevel API, implementing skip connections `(0.4/1)`\n",
    "В этом разделе посмотрим на особенности обучения глубоких сетей. Эксперименты будем делать на мнисте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0Dpa7Zk2knU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Interesting fact: torchvision transforms work on GPUs\n",
    "transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.view(-1))])\n",
    "\n",
    "dataset_train = MNIST(\n",
    "    root='mnist',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "dataset_test = MNIST(root='mnist', train=False, transform=transform)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, shuffle=True, batch_size=32)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, shuffle=True, batch_size=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruqS0RZ83Z1P"
   },
   "source": [
    "Допишите код полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hfe_9hN82p5G"
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_size, activation):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        l0 = nn.Linear(dataset_train[0][0].shape[0], hidden_size)\n",
    "        self.weights = [l0.weight]\n",
    "        self.layers = [l0]\n",
    "\n",
    "        # <your code here>\n",
    "\n",
    "        self.seq = nn.Sequential(*self.layers)\n",
    "\n",
    "        for l in self.weights:\n",
    "            l.retain_grad()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.seq(x)\n",
    "        return F.log_softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb10eylm3quu"
   },
   "source": [
    "Train eval loop, с логированием градиентов (тут дописывать не надо, но можно почитать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lB_dAKQ3p1O"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    loss_log, acc_log = [], []\n",
    "    grads = [[] for l in model.weights]\n",
    "    model.train()\n",
    "    for x_batch, y_batch in dataloader_train:\n",
    "        # data preparation\n",
    "        data = torch.from_numpy(x_batch.astype(np.float32))\n",
    "        target = torch.from_numpy(y_batch.astype(np.int64))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        pred = torch.max(output, 1)[1].numpy()\n",
    "        acc = np.mean(pred == y_batch)\n",
    "        acc_log.append(acc)\n",
    "\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        # make a step\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "\n",
    "        for g, l in zip(grads, model.weights):\n",
    "            g.append(np.linalg.norm(l.grad.numpy()))\n",
    "    return loss_log, acc_log, grads\n",
    "\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "\n",
    "    points = np.array(val_history)\n",
    "\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(model, optimizer, n_epochs):\n",
    "    train_log, train_acc_log = [], []\n",
    "    val_log, val_acc_log = [], []\n",
    "    grads_log = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {} of {}\".format(epoch, n_epochs))\n",
    "        train_loss, train_acc, grads = train_epoch(model, optimizer)\n",
    "        if grads_log is None:\n",
    "            grads_log = grads\n",
    "        else:\n",
    "            for a, b in zip(grads_log, grads):\n",
    "                a.extend(b)\n",
    "\n",
    "        val_loss, val_acc = test(model)\n",
    "\n",
    "        train_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "\n",
    "        steps = len(dataset_train) / dataloader_train.batch_size\n",
    "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "        val_acc_log.append((steps * (epoch + 1), np.mean(val_acc)))\n",
    "\n",
    "        # display all metrics\n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)\n",
    "        plot_history(train_acc_log, val_acc_log, title='accuracy')\n",
    "\n",
    "        plt.figure()\n",
    "        all_vals = []\n",
    "        for i, g in enumerate(grads_log):\n",
    "            w = np.ones(100)\n",
    "            w /= w.sum()\n",
    "            vals = np.convolve(w, g, mode='valid')\n",
    "            plt.semilogy(vals, label=str(i+1), color=plt.cm.coolwarm((i / len(grads_log))))\n",
    "            all_vals.extend(vals)\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.eval()\n",
    "    for x_batch, y_batch in dataloader_test:\n",
    "        data = torch.from_numpy(x_batch.astype(np.float32))\n",
    "        target = torch.from_numpy(y_batch.astype(np.int64))\n",
    "\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        pred = torch.max(output, 1)[1].numpy()\n",
    "        acc = np.mean(pred == y_batch)\n",
    "        acc_log.append(acc)\n",
    "\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAClSTlK5lpU"
   },
   "source": [
    "**Задание 1:**\n",
    "* Обучите сети глубины 10 и больше с сигмоидой в качестве активации. Исследуйте, как глубина влияет на качество обучения и поведение градиентов на далеких от выхода слоях.\n",
    "* Теперь замените активацию на ReLU и посмотрите, что получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAFHUQEC5lpW"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_mZPVXu5lpX"
   },
   "source": [
    "Теперь попробуем добавить в сеть skip-connections (по примеру ResNet) вместо замены сигмоиды на relu и посмотрим, что получится. Запихнуть все слои в nn.Sequential и просто их применить теперь не получится - вместо этого мы их применим вручную. Но положить их в отдельный модуль nn.ModuleList все равно нужно, иначе torch не сможет их найти и оптимизировать.\n",
    "\n",
    "**Задание 2:** допишите недостающую часть кода ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32G8g-nK5lpX"
   },
   "outputs": [],
   "source": [
    "class FFN_with_skip_connection(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_size, activation):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        l0 = nn.Linear(dataset_train[0][0].shape[0], hidden_size)\n",
    "        self.weights = [l0.weight]\n",
    "        self.layers = [l0]\n",
    "\n",
    "        for i in range(1, n_layers - 1):\n",
    "            l = nn.Linear(hidden_size, hidden_size)\n",
    "            self.layers.append(l)\n",
    "            self.weights.append(l.weight)\n",
    "\n",
    "        l = nn.Linear(hidden_size, 10)\n",
    "        self.layers.append(l)\n",
    "        self.weights.append(l.weight)\n",
    "\n",
    "        self.seq = nn.Sequential(*self.layers)\n",
    "\n",
    "        for l in self.weights:\n",
    "            l.retain_grad()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # <your code here>\n",
    "\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWaHXHC25lpX"
   },
   "source": [
    "Убедимся, что такая сеть отлично учится даже на большом числе слоев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0t5AIQ25lpX"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oikbV3efY8yz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Fine Tuning `(0.4/1)`\n",
    "Для многих прикладных задач не существует больших датасетов с хорошей разметкой.\n",
    "Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n",
    "\n",
    "Такой прием называют **Transfer Learning** или **Finetuning**.\n",
    "\n",
    "В сверточных сетях для классификации выделяют две части:\n",
    "- тело сети -- это набор сверток и пулингов (convolutions and poolings)\n",
    "- голову -- это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n",
    "\n",
    "\n",
    "Вычислительно простым вариантом finetuning является переучивание головы сети.\n",
    "\n",
    "\n",
    "Нам потребуется [предобученная модель](http://pytorch.org/docs/master/torchvision/datasets.html#torchvision-datasets) и датасет для нашей задачи.\n",
    "\n",
    "Предлагется воспользоваться моделью для ImageNet и датасетом  https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
    "\n",
    "\n",
    "В датасете содержатся картинки двух классов (`ants` и `bees`) разных размеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a1J3RKxY8y0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# На Windows придется скачать архив по ссылке (~45Mb) и распаковать самостоятельно\n",
    "!wget --quiet --show-progress \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "!unzip -q ./hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGVsiVQBY8y4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Загрузчик данных -- одна из важных компонент для эффективного обучения нейронных сетей:\n",
    "асинхронная загрузка и быстрая предобработка важны для полного использования GPU. В pytorch для этого есть https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "Пример использования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Emt8XDoY8y7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmUYoy7XY8zD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.1)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5LNGH6DY8zK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# обратите внимание на сохранение лучшей версии весов сети\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels).type(torch.float)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Elapsed {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkG9Pa3mY8zP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# torchvision содержит ряд моделей с претрейненными весами:\n",
    "[m for m in dir(models) if not m.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1ZvVhmnY8zS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "# hint: вы можете изучить устройство любого объекта в python пользуясь интерактивностью интерпретатора и методом dir()\n",
    "\n",
    "# Список слоев модели можно получить с помощью обхода\n",
    "# for x in model_ft.named_modules():\n",
    "#    print(x[0], x[1])\n",
    "\n",
    "# TODO: подмените в модели последний слой, чтобы она работала для двух классов\n",
    "\n",
    "NotImplemented\n",
    "\n",
    "# TODO: выберите, какие параметры дообучать. Результат получается лучше если дообучать всё или только последний слой? Почему?\n",
    "# например, выключить обучение всех параметров можно при помощи этого кода:\n",
    "# for params in model_ft.parameters():\n",
    "#     params.requires_grad = False\n",
    "\n",
    "params_to_train = NotImplemented\n",
    "\n",
    "# use GPU if you have it\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create optimizer on the selected parameters\n",
    "optimizer_ft = optim.SGD(params_to_train, lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cy1wlPmxY8zW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_ft = train_model(\n",
    "    model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25\n",
    ")\n",
    "\n",
    "# если всё сделано правильно, то точность на валидации должна быть больше 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LR4Fi3qTY8zc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: напишите функцию, прогоняющую модель на нескольких примерах из валидационной выборки\n",
    "# Отобразите картинки и предсказания\n",
    "\n",
    "def visualize(model, num_images=10):\n",
    "    NotImplemented\n",
    "\n",
    "visualize(model_ft)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "hse_dl_year": "2021-fall",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
